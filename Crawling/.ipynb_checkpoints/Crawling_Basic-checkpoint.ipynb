{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 크롤링 fast view ]\n",
    "\n",
    "1. 크롤링할 html 코드를 가져온다. (request.get())\n",
    "2. 파싱한다. (BeautifulSoup(res.content, 'html.parser')\n",
    "3. 특정 데이터 선택\n",
    "4. 출력(get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) HTML 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 크롤링이란?\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n",
      " [1] 크롤링이란?\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id = 'title'> [1] 크롤링이란?</h1>\\\n",
    "                <p class = 'cssstly'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id = 'body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "data1 = soup.find('h1')    # find 함수를 사용하게되면, 검색된 tag를 먼저 사용한 내용이 출력된다.\n",
    "data2 = soup.find_all('p') # find_all 함수를 사용하게되면, 검색된 tag를 사용한 모든 내용이 리스트형태로 변수에 저장된다.\n",
    "data3 = soup.find('p', attrs = {'align' : 'center'} ) # find함수의 attrs 속성을 사용하여 검색된 tag의 특정 속성의 값을 가진 내용만 변수에 저장된다.\n",
    "data4 = soup.find(id = 'title') # id 또한 tag를 구분하기위한 tag임으로 왼쪽과 같이 사용할 수있다. (크롤링시 유용)\n",
    "                                # data4 = soup.find('p', attrs = {'id' : 'body'})로도 쓸 수 있다.\n",
    "data5 = soup.find(id = 'body')\n",
    "\n",
    "\n",
    "print(data1.get_text())\n",
    "\n",
    "for item in data2:\n",
    "    print(item.get_text())\n",
    "                                \n",
    "print(data3.get_text())\n",
    "\n",
    "print(data4.get_text())\n",
    "\n",
    "print(data5.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) CSS의 class를 이용한 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = \"<html>\\\n",
    "            <body>\\\n",
    "                <h1 id = 'title'> [1] 크롤링이란?</h1>\\\n",
    "                <p class = 'cssstly'>웹페이지에서 필요한 데이터를 추출하는 것</p>\\\n",
    "                <p id = 'body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\\\n",
    "            </body>\\\n",
    "        </html>\"\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. class 이름 그대로 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'웹페이지에서 필요한 데이터를 추출하는 것'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = soup.find('p', 'cssstly')\n",
    "data1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. class_로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'웹페이지에서 필요한 데이터를 추출하는 것'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = soup.find('p', class_ = 'cssstly')\n",
    "data2.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 속성값 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'웹페이지에서 필요한 데이터를 추출하는 것'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = soup.find('p', attrs = {'class' : 'cssstly'})\n",
    "data3.get_text()             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
