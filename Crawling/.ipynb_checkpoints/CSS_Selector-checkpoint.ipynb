{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ CSS Selector 사용법 ]\n",
    "   \n",
    "- <b>`select()`</b> 안에 태그 또는 CSS class 이름 등을 넣어주면 된다.\n",
    "\n",
    "\n",
    "- <b>`select()`</b> 에서는 \n",
    "    - class 앞에 <b>`.`</b>\n",
    "    - id 앞에 <b>`#`</b>을 붙여준다.\n",
    "    \n",
    "    \n",
    "- 태그와 클래스, 클래스와 클래스는 <b>`.`</b>으로 연결한다.\n",
    "\n",
    "\n",
    "- <b>`select()`</b>는 <b>`find_all()`</b>과 동일하게 list형태로 값을 반환한다.\n",
    "\n",
    "\n",
    "- select 사용 예제\n",
    "    - tag 이름으로 선택  \n",
    "    ```python\n",
    "    select('a')\n",
    "    ```\n",
    "        \n",
    "    - tag + class 이름으로 선택\n",
    "    ```python\n",
    "    select('h3.tit_view')\n",
    "    ```\n",
    "    - tag + class 여러개가 한 줄에 있을 경우\n",
    "    ```python\n",
    "    select('div.ah_roll_area.PM_CL_realtime')\n",
    "    ```\n",
    "    - class 이름만 선택\n",
    "    ```python\n",
    "    select('.tit_view')\n",
    "    ```\n",
    "    - id 로만 선택\n",
    "    ```python\n",
    "    select('#video-title')\n",
    "    ```\n",
    "    - class, id 를 복합 선택\n",
    "    ```python\n",
    "    select('div.tit_view div#link_txt')\n",
    "    ```\n",
    "    - 상위, 하위 태그를 한꺼번에 선택\n",
    "    ```python\n",
    "    select('html head title')\n",
    "    select('html>head>title')\n",
    "    ```\n",
    "    \n",
    "- TIP! 크롬 개발자 모드에서 Copy Selector로 추측가능\n",
    "\n",
    "---\n",
    "### (1) 예제1 ( 태그 가져오기 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갤럭시Z폴드2, 9월1일 펴진다\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=105&oid=011&aid=0003789378'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "\n",
    "res = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# h3_find = soup.find(id = 'articleTitle')\n",
    "\n",
    "h3_select = soup.select('h3#articleTitle')\n",
    "for item in h3_select:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### (2) 예제 2 ( 하위 태그 선택 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갤럭시Z폴드2, 9월1일 펴진다 : 네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=105&oid=011&aid=0003789378'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "\n",
    "res = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "title_select = soup.select('html  head  title')\n",
    "\n",
    "for item in title_select:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 또한, html > ... > title, 즉 html에서 title 태그까지의 과정을 생략해도 정상적으로 출력된다.\n",
    "\n",
    "\n",
    "- 아래 예시는 html 태그와 title 태그의 중간 과정인 head 태그를 생략해서 작성한 경우다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갤럭시Z폴드2, 9월1일 펴진다 : 네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "title_select = soup.select('html title')\n",
    "\n",
    "for item in title_select:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만, <b>`>`</b>(꺽쇠) 기호를 이용하여 하위 태그를 표시하는 경우, 생략이 불가능하다.<br>따라서, 위의 예시처럼 과정 생략이 불가능하다.\n",
    "\n",
    "\n",
    "- 위의 예시에서 <b>`>`</b>을 이용하여 과정생략을 나타낼 경우 아무것도 출력되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_select = soup.select('html > title')\n",
    "\n",
    "for item in title_select:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### (3) 예제 3 ( 특정 class 를 가진 내용만 가져오기 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스홈\n",
      "속보\n",
      "정치\n",
      "경제\n",
      "사회\n",
      "생활/문화\n",
      "세계\n",
      "IT/과학\n",
      "오피니언\n",
      "포토\n",
      "TV\n",
      "랭킹뉴스\n",
      "검색\n"
     ]
    }
   ],
   "source": [
    "title_select = soup.select('.tx')\n",
    "\n",
    "for item in title_select:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 예제 4 ( 특정 id 를 가진 내용만 가져오기 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_select = soup.select('#articleTitle')\n",
    "\n",
    "for item in title_select:\n",
    "    print(item.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) find -> select로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위 :블랙팬서\n",
      "2위 :채드윅 보스만\n",
      "3위 :블랙팬서 사망\n",
      "4위 :채드윅 보스만 사망\n",
      "5위 :이도진\n",
      "6위 :블랙팬서2\n",
      "7위 :네이버 스마트주문\n",
      "8위 :이제마스터디카페\n",
      "9위 :드라마 앨리스\n",
      "10위 :산다라박\n",
      "11위 :와칸다 포에버\n",
      "12위 :이낙연\n",
      "13위 :한성관\n",
      "14위 :이낙연 관련주\n",
      "15위 :변성남\n",
      "16위 :원더풀 고스트\n",
      "17위 :신국\n",
      "18위 :이호철\n",
      "19위 :최란\n",
      "20위 :창원 한성관\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://datalab.naver.com/keyword/realtimeList.naver?where=main'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "\n",
    "\n",
    "res = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# 보통은 상위 태그를 find로 먼저 가져와서 전체적인 코드를 먼저 확인하는편이다.\n",
    "li = soup.find_all('li', 'ranking_item')\n",
    "\n",
    "\n",
    "for item in li:\n",
    "        rank = item.find('span', 'item_num')\n",
    "        title = item.find('span', 'item_title')\n",
    "        print(rank.get_text()+'위 :'+ title.get_text())\n",
    "    \n",
    "\n",
    "#content > div > div.selection_area > div.selection_content > div.field_list > div > div > ul:nth-child(1) > li:nth-child(1) > div > span.item_title_wrap > span.item_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1위 :블랙팬서\n",
      "2위 :채드윅 보스만\n",
      "3위 :블랙팬서 사망\n",
      "4위 :채드윅 보스만 사망\n",
      "5위 :이도진\n",
      "6위 :블랙팬서2\n",
      "7위 :네이버 스마트주문\n",
      "8위 :이제마스터디카페\n",
      "9위 :드라마 앨리스\n",
      "10위 :와칸다 포에버\n",
      "11위 :산다라박\n",
      "12위 :이낙연\n",
      "13위 :더불어민주당 당대표\n",
      "14위 :이낙연 관련주\n",
      "15위 :변성남\n",
      "16위 :원더풀 고스트\n",
      "17위 :신국\n",
      "18위 :한성관\n",
      "19위 :앨리스\n",
      "20위 :이호철\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://datalab.naver.com/keyword/realtimeList.naver?where=main'\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "\n",
    "\n",
    "res = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# li = soup.select('li.ranking_item')\n",
    "#\n",
    "#\n",
    "# for item in li:\n",
    "#        rank = item.select('span.item_num')\n",
    "#        title = item.select('span.item_title')\n",
    "#        print(rank[0].get_text()+'위 :'+ title[0].get_text())\n",
    "\n",
    "\n",
    "for item in soup.select('li.ranking_item'):\n",
    "       rank = item.select('span.item_num')\n",
    "       title = item.select('span.item_title')\n",
    "       print(rank[0].get_text()+'위 :'+ title[0].get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
